{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28b26c69",
      "metadata": {},
      "source": [
        "# Create a FAISS based Vector Index for DBCopilot with AzureML\n",
        "We'll walk through setting up an AzureML Pipeline which grounding a Database into a LangChain-compatible FAISS Vector Index and create the Prompt flow to consume this index to serve as a DBCopilot chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "345e6aa4",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# %pip install azure-ai-ml\n",
        "# %pip install -U 'azureml-rag[faiss]>=0.1.11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "038912d8",
      "metadata": {
        "gather": {
          "logged": 1689182662643
        }
      },
      "outputs": [],
      "source": [
        "# If `import win32file` fails with a DLL error then run the following and restart kernel:\n",
        "# %pip uninstall -y pywin32\n",
        "# %conda install -y --force-reinstall pywin32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "734d8c1a-9bc2-4957-9251-c529e3f1b826",
      "metadata": {
        "gather": {
          "logged": 1689182662703
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# System imports\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ebd2ec7e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\davidtorres\\Projects\\Sample-Code\\AzureML\\DBCopilot\\.env\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# retrieve and print environment variables\n",
        "#\n",
        "# load environment variables from .env file (which should be in .gitignore)\n",
        "# this is a way to keep sensitive information out of the codebase\n",
        "# the following code allows for .env file to be in same directory as script\n",
        "# or you can specify the path relative to the notebook to the .env file\n",
        "from os.path import join\n",
        "from dotenv import load_dotenv\n",
        "dotenv_path = join(os.getcwd(), '.env')\n",
        "print(dotenv_path)\n",
        "load_dotenv(dotenv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f3b8ad4a-952d-4091-a5b7-7196e1e3c5f6",
      "metadata": {
        "gather": {
          "logged": 1689182662773
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Execution Variables\n",
        "\n",
        "# Tenent and Application Id settings\n",
        "tenant_id = os.getenv('TENANT_ID')                                      # \"<enter the tenent id>\"                   << Used for EnvironmentCredential\n",
        "application_client_id = os.getenv('CLIENT_ID')                          # \"<enter application client id>\"           << Used for EnvironmentCredential\n",
        "application_client_secret = os.getenv('CLIENT_SECRET')                  # \"<enter application client secret>\"       << Used for EnvironmentCredential\n",
        "\n",
        "# Azure Workspace settings\n",
        "subscription_id = os.getenv('SUBSCRIPTION_ID')                          # \"<enter the subscription id>\"             << Used in workspace.json settings file\n",
        "resource_group_name = os.getenv('RESOURCE_GROUP')                       # \"<enter the resource group name>\"         << Used in workspace.json settings file\n",
        "workspace_name = os.getenv('WORKSPACE_NAME')                            # \"<enter the azure ml workspace name>\"     << Used in workspace.json settings file\n",
        "default_compute=os.getenv('CLUSTER_NAME')                               # \"<enter dedicate compute cluster name>\"   << !! Only works with dedicate compute cluster\n",
        "                                                                        # \"serverless\"                              << !! \"serverless\" and \"named\" compute instances are \n",
        "                                                                        #  NOTE >>>>                                << !! currently causing failure in generate_meta_embedding step\n",
        "\n",
        "# Azure OpenAI settings\n",
        "aoai_connection_name = \"Default_AzureOpenAI\"                            # \"<default is Default_AzureOpenAI>\"        << Use the Azure OpenAI resource connection name\n",
        "aoai_embedding_model_name = \"text-embedding-ada-002\"                    # \"<default to text-embedding-ada-002\"      << Recommendation is text-embedding-ada-002\n",
        "aoai_completion_model_name = \"gpt-35-turbo\"                             # \"<default to gpt-35-turbo>\"               << Recommendation is gpt-35-turbo\n",
        "\n",
        "# Set vector index asset name\n",
        "datastore_name = os.getenv('DATA_STORE_NAME')                           # \"<enter the name of the Datastore>\"       << The database registered in Data > Datastore to create embeddings\n",
        "datastore_scope = \"array\"                                                 # \"<enter the scope to be indexed>\"       << \"all\" = all tables, anything else need a list of tables/views \n",
        "data_asset_name = f\"{datastore_name}_{datastore_scope}_llm_index\"       # \"<enter the vector index suffix>\"         << The index to be created in Data > Data Asset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ce2e8d-c46e-4ff1-b5a4-506ea9914503",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "If datastore_scope is not \"all\" then create a list of tables to be in the scope of the vector index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "59e95ca4-dbb6-4750-b192-2547fd0ccb18",
      "metadata": {
        "gather": {
          "logged": 1689182662829
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables to Index: ['[SalesLT].[Address]', '[SalesLT].[Customer]', '[SalesLT].[CustomerAddress]']\n"
          ]
        }
      ],
      "source": [
        "database_tables = None\n",
        "\n",
        "if datastore_scope != \"all\":\n",
        "    tables = []\n",
        "    tables.append('[SalesLT].[Address]')\n",
        "    tables.append('[SalesLT].[Customer]')\n",
        "    tables.append('[SalesLT].[CustomerAddress]')\n",
        "    # tables.append('[SalesLT].[Product]')\n",
        "    # tables.append('[SalesLT].[ProductCategory]')\n",
        "    # tables.append('[SalesLT].[ProductDescription]')\n",
        "    # tables.append('[SalesLT].[ProductModel]')\n",
        "    # tables.append('[SalesLT].[ProductModelProductDescription]')\n",
        "    database_tables = str(tables)\n",
        "\n",
        "print(f\"Tables to Index: {database_tables}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1a99955c",
      "metadata": {},
      "source": [
        "## Create client for AzureML Workspace\n",
        "\n",
        "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3b80ce-8f77-4e9c-adb3-2cc721b1978d",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Get `credential` to create `MLClient`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "58590635-d105-4de9-bac8-777e74235065",
      "metadata": {
        "gather": {
          "logged": 1689182664733
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AccessToken(token='eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6Ii1LSTNROW5OUjdiUm9meG1lWm9YcWJIWkdldyIsImtpZCI6Ii1LSTNROW5OUjdiUm9meG1lWm9YcWJIWkdldyJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuYXp1cmUuY29tIiwiaXNzIjoiaHR0cHM6Ly9zdHMud2luZG93cy5uZXQvNzJmOTg4YmYtODZmMS00MWFmLTkxYWItMmQ3Y2QwMTFkYjQ3LyIsImlhdCI6MTY5MzU3ODg3NiwibmJmIjoxNjkzNTc4ODc2LCJleHAiOjE2OTM2NjU1NzYsImFpbyI6IkUyRmdZRGd5b1ZGbVZ3UFArNURuZjJTWDJpMTRCUUE9IiwiYXBwaWQiOiJiZDhlNDU3Ni0zYjA2LTQ5MTgtYmU3ZC0wYjZhODE3NTA5ZWYiLCJhcHBpZGFjciI6IjEiLCJpZHAiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC83MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDcvIiwiaWR0eXAiOiJhcHAiLCJvaWQiOiI4Y2Q2OWM1Yy04YzU4LTQ5MTgtOTk2Zi1mOTI0ZmFlN2M4NmMiLCJyaCI6IjAuQVJvQXY0ajVjdkdHcjBHUnF5MTgwQkhiUjBaSWYza0F1dGRQdWtQYXdmajJNQk1hQUFBLiIsInN1YiI6IjhjZDY5YzVjLThjNTgtNDkxOC05OTZmLWY5MjRmYWU3Yzg2YyIsInRpZCI6IjcyZjk4OGJmLTg2ZjEtNDFhZi05MWFiLTJkN2NkMDExZGI0NyIsInV0aSI6IjVpaWpTWWFJOUVHeGNOSmtUcjBDQUEiLCJ2ZXIiOiIxLjAiLCJ4bXNfdGNkdCI6MTI4OTI0MTU0N30.THuBZWAVX_mKPwYqyDwcfGldXLashgmSmOR5KJOeJpK60qLVUlfxYaWtmKnCMPccLAFclfzj-DAqCCySj69EkiAxzIzcbk2Sqh9rlC3NToA5xPnuJgOUKF5qp1OgCkHFuJejnl-u4nH1qFzeKpevsHLitRN2IZ0ORwtG4CjXAVKxY25p31Y0XSRtFxwM9E88dZILPgWMgO9c_BMsE_5GEkHrEhgJca-ekn-6JCrAlcK_opPsdtzQzk3wBOre2LrwbNW5zSYHkhTnaeAPeRyR698JXMnFlFyePs8U0R8TqfhBsHlEOlSDTI7BtMnDYMDTGcDANXh_HB_Ea25YfeyD9w', expires_on=1693665575)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.identity import DefaultAzureCredential, ClientSecretCredential, EnvironmentCredential, AzureCliCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Create ClientSecretCredential as default credential\n",
        "# Service Principal (Application Client) must have Contributor role on the Azure ML Workspace \n",
        "try:\n",
        "    ## Set expected environment variables\n",
        "    os.environ['AZURE_TENANT_ID'] = tenant_id\n",
        "    os.environ['AZURE_CLIENT_ID'] = application_client_id\n",
        "    os.environ['AZURE_CLIENT_SECRET'] = application_client_secret\n",
        "    os.environ['AZURE_AUTHORITY_HOST'] = 'https://login.microsoftonline.com'\n",
        "    credential = ClientSecretCredential(tenant_id=tenant_id, client_id=application_client_id, client_secret=application_client_secret)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    print('Try DefaultAzureCredential creation')\n",
        "    # Fall back to DefaultAzureCredential, if ClientSecretCredential does not work\n",
        "    # DefaultAzureCredential will look for credientials sequentially see docs at\n",
        "    # https://learn.microsoft.com/en-us/dotnet/api/azure.identity.defaultazurecredential\n",
        "    try:\n",
        "        credential = DefaultAzureCredential()\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "\n",
        "credential.get_token(\"https://management.azure.com/.default\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb5c8f0",
      "metadata": {},
      "source": [
        "Create `MLClient` to interact with AzureML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cbb39686-ca94-4767-95ce-381e249f942d",
      "metadata": {
        "gather": {
          "logged": 1689182666559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Falling back to use azure cli login credentials.\n",
            "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
            "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLClient(credential=<azure.identity._credentials.client_secret.ClientSecretCredential object at 0x000001C0396B6EC0>,\n",
            "         subscription_id=8878a446-3d3e-44c2-bae5-09fd1d17e6d6,\n",
            "         resource_group_name=common-ai-dev,\n",
            "         workspace_name=common-ai-dev-ml)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    ml_client= MLClient(credential=credential, subscription_id=subscription_id, resource_group_name=resource_group_name, workspace_name=workspace_name)\n",
        "except Exception as ex:\n",
        "    raise Exception(\"Failed to create MLClient from config file. Please verify AzureML Workspace details and update Execution Variables above.\") from ex\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "print(ml_client)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "30906d39",
      "metadata": {},
      "source": [
        "## Azure OpenAI\n",
        "\n",
        "We recommend using gpt-35-turbo model to get good quality QAs. [Follow these instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) to setup an Azure OpenAI Instance and deploy the model. Once you have the model deployed in AOAI you can specify your Model name and Deployment name below.\n",
        "\n",
        "We will use the automatically created `Default_AzureOpenAI` connection, change `aoai_connection_name` to use your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129ac0b7",
      "metadata": {
        "gather": {
          "logged": 1689182667206
        }
      },
      "outputs": [],
      "source": [
        "from azureml.rag.utils.connections import get_connection_by_name_v2\n",
        "\n",
        "try:\n",
        "    # Get the Azure OpenAI Connection\n",
        "    aoai_connection = get_connection_by_name_v2(ws, aoai_connection_name)\n",
        "    # Get the Azure OpenAI connection id\n",
        "    aoai_connection_id = aoai_connection[\"id\"]\n",
        "    # Print Azure OpenAI connection info\n",
        "    print(f\"Azure OpenAI connection: \\n{json.dumps(aoai_connection, indent=4)}\")\n",
        "    \n",
        "except Exception as ex:\n",
        "    print(f'Exception: {ex}')\n",
        "    print(f'Unable to create a connection to the Azure OpenAI resource named: {aoai_connection_name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac0df32-83a0-4e13-ba94-bf5e00e812bc",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **embedding** model has been deployed (recommendation is `text-embedding-ada-002`)\n",
        "\n",
        "This cell will fail if there is not deployment for the embeddings model, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a model with Azure OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c045de88",
      "metadata": {
        "gather": {
          "logged": 1689182667402
        }
      },
      "outputs": [],
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "try:\n",
        "    aoai_embedding_deployment_name = infer_deployment(aoai_connection, aoai_embedding_model_name)\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is '{aoai_embedding_deployment_name}'\")\n",
        "except Exception as ex:\n",
        "    print(f\"Exception: {ex}\")\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is not found.\")\n",
        "    print(f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "450868d1-6deb-428b-81ad-8c2203da31bd",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **completion** model has been deployed (recommendation is `gpt-35-turbo`)\n",
        "\n",
        "The following cell will fail if a **completion** model is not deployed, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a **completion** model with Azure OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e5cc13",
      "metadata": {
        "gather": {
          "logged": 1689182667467
        }
      },
      "outputs": [],
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "try:\n",
        "    aoai_completion_deployment_name = infer_deployment(aoai_connection, aoai_completion_model_name)\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is '{aoai_completion_deployment_name}'\")\n",
        "except Exception as ex:\n",
        "    print(f\"Exception: {ex}\")\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is not found.\")\n",
        "    print(f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\")\n",
        "\n",
        "# Create LLM completion config in URI form which the AzureML embeddings components expect as input.\n",
        "llm_completion_config = f'{{\"type\":\"azure_open_ai\",\"model_name\":\"{aoai_completion_model_name}\",\"deployment_name\":\"{aoai_completion_deployment_name}\",\"temperature\":0,\"max_tokens\":\"1500\"}}'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "56878876",
      "metadata": {},
      "source": [
        "### Setup Pipeline Job\n",
        "\n",
        "The Components are published to a [Registry](https://learn.microsoft.com/azure/machine-learning/how-to-manage-registries?view=azureml-api-2&tabs=cli), `azureml`, which should have access to by default, it can be accessed from any Workspace.\n",
        "In the below cell we get the Component Definitions from the `azureml` registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a3752a",
      "metadata": {
        "gather": {
          "logged": 1689182667820
        }
      },
      "outputs": [],
      "source": [
        "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
        "\n",
        "db_copilot_component = ml_registry.components.get(\"llm_ingest_db_to_faiss\", label=\"latest\")\n",
        "\n",
        "print(db_copilot_component)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209700d2",
      "metadata": {
        "gather": {
          "logged": 1689182668206
        }
      },
      "outputs": [],
      "source": [
        "# Create the pipeline\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "@pipeline(\n",
        "    name=f\"db_copilot_vector_pipeline_faiss\",\n",
        "    default_compute=default_compute\n",
        ")\n",
        "def db_copilot_vector_pipeline_faiss(\n",
        "    aoai_connection: str,\n",
        "    db_datastore: str,\n",
        "    embeddings_model: str,\n",
        "    chat_aoai_deployment_name: str,\n",
        "    embedding_aoai_deployment_name: str,\n",
        "    mlindex_dataset_name: str,\n",
        "    selected_tables: str = None,\n",
        "    max_sampling_rows: int = 3,\n",
        "):\n",
        "    db_copilot_component(\n",
        "        db_datastore=db_datastore,\n",
        "        embeddings_model=embeddings_model,\n",
        "        chat_aoai_deployment_name=chat_aoai_deployment_name,\n",
        "        embedding_aoai_deployment_name=embedding_aoai_deployment_name,\n",
        "        embeddings_dataset_name=mlindex_dataset_name,\n",
        "        embedding_connection=aoai_connection,\n",
        "        llm_connection=aoai_connection,\n",
        "        selected_tables=selected_tables,\n",
        "        max_sampling_rows=max_sampling_rows,\n",
        "    )\n",
        "    return {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6682ea80",
      "metadata": {
        "gather": {
          "logged": 1689182668337
        }
      },
      "outputs": [],
      "source": [
        "# Create pipeline job\n",
        "pipeline_job = db_copilot_vector_pipeline_faiss(\n",
        "    aoai_connection=aoai_connection_id,\n",
        "    db_datastore=f\"azureml://datastores/{datastore_name}\",\n",
        "    embeddings_model=f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_embedding_model_name}\",\n",
        "    chat_aoai_deployment_name=aoai_completion_deployment_name,\n",
        "    embedding_aoai_deployment_name=aoai_embedding_deployment_name,\n",
        "    mlindex_dataset_name=data_asset_name,\n",
        "    selected_tables=\"[\\\"[SalesLT].[Product]\\\"]\",\n",
        "    max_sampling_rows=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00fd418",
      "metadata": {
        "gather": {
          "logged": 1689182668399
        }
      },
      "outputs": [],
      "source": [
        "# These are added so that in progress index generations can be listed in UI, this tagging is done automatically by UI.\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = data_asset_name\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Database\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d9b2be",
      "metadata": {
        "gather": {
          "logged": 1689182670964
        }
      },
      "outputs": [],
      "source": [
        "# Submit pipeline job\n",
        "running_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=str.lower(f\"{datastore_name}_{datastore_scope}_dbcopilot_pipeline\")\n",
        ")\n",
        "running_pipeline_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c71f975c",
      "metadata": {
        "gather": {
          "logged": 1689182301371
        }
      },
      "outputs": [],
      "source": [
        "ml_client.jobs.stream(running_pipeline_job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d098fccd",
      "metadata": {},
      "source": [
        "## Use DBCopilot with Promptflow\n",
        "After the pipeline complete, it will create a promptflow which could be used to chat with the db."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
