{
  "cells": [
    {
      "cell_type": "markdown",
<<<<<<< HEAD
      "source": [
        "# Create a FAISS based Vector Index for DBCopilot with AzureML\n",
        "We'll walk through setting up an AzureML Pipeline which grounding a Database into a LangChain-compatible FAISS Vector Index and create the Prompt flow to consume this index to serve as a DBCopilot chatbot."
      ],
      "metadata": {},
      "id": "28b26c69"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-ai-ml\n",
        "%pip install -U 'azureml-rag[faiss]>=0.1.11'"
      ],
      "outputs": [],
      "execution_count": null,
=======
      "id": "28b26c69",
      "metadata": {},
      "source": [
        "# Create a FAISS based Vector Index for DBCopilot with AzureML\n",
        "We'll walk through setting up an AzureML Pipeline which grounding a Database into a LangChain-compatible FAISS Vector Index and create the Prompt flow to consume this index to serve as a DBCopilot chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "345e6aa4",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
<<<<<<< HEAD
      "id": "345e6aa4"
    },
    {
      "cell_type": "code",
      "source": [
        "# If `import win32file` fails with a DLL error then run the following and restart kernel:\n",
        "# %pip uninstall -y pywin32\n",
        "# %conda install -y --force-reinstall pywin32"
      ],
      "outputs": [],
      "execution_count": null,
=======
      "outputs": [],
      "source": [
        "%pip install azure-ai-ml\n",
        "%pip install -U 'azureml-rag[faiss]>=0.1.11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "038912d8",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "gather": {
          "logged": 1689182662643
        }
      },
<<<<<<< HEAD
      "id": "038912d8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
=======
      "outputs": [],
      "source": [
        "# If `import win32file` fails with a DLL error then run the following and restart kernel:\n",
        "# %pip uninstall -y pywin32\n",
        "# %conda install -y --force-reinstall pywin32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734d8c1a-9bc2-4957-9251-c529e3f1b826",
      "metadata": {
        "gather": {
          "logged": 1689182662703
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
>>>>>>> c9d8d67 (Updates to sample code)
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
<<<<<<< HEAD
        },
        "gather": {
          "logged": 1689182662703
        }
      },
      "id": "734d8c1a-9bc2-4957-9251-c529e3f1b826"
    },
    {
      "cell_type": "code",
=======
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f57dd818",
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "# retrieve and print environment variables\n",
        "#\n",
        "# load environment variables from .env file (which should be in .gitignore)\n",
        "# this is a way to keep sensitive information out of the codebase\n",
        "# the following code allows for .env file to be in same directory as script\n",
        "# or you can specify the path relative to the notebook to the .env file\n",
        "from os.path import join\n",
        "from dotenv import load_dotenv\n",
        "dotenv_path = join(os.getcwd(), '.env')\n",
        "load_dotenv(dotenv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b8ad4a-952d-4091-a5b7-7196e1e3c5f6",
      "metadata": {
        "gather": {
          "logged": 1689182662773
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "# Execution Variables\n",
        "\n",
        "# Tenent and Application Id settings\n",
<<<<<<< HEAD
        "tenent_id = \"<enter the tenent id>\"                                     # \"<enter the tenent id>\"                   << Used for EnvironmentCredential\n",
=======
        "tenant_id = \"<enter the tenent id>\"                                     # \"<enter the tenent id>\"                   << Used for EnvironmentCredential\n",
>>>>>>> c9d8d67 (Updates to sample code)
        "application_client_id = \"<enter application client id>\"                 # \"<enter application client id>\"           << Used for EnvironmentCredential\n",
        "application_client_secret = \"<enter application client secret>\"         # \"<enter application client secret>\"       << Used for EnvironmentCredential\n",
        "\n",
        "# Azure Workspace settings\n",
        "subscription_id = \"<enter the subscription id>\"                         # \"<enter the subscription id>\"             << Used in workspace.json settings file\n",
        "resource_group_name = \"<enter the resource group name>\"                 # \"<enter the resource group name>\"         << Used in workspace.json settings file\n",
        "azure_ml_workspace_name = \"<enter the azure ml workspace name>\"         # \"<enter the azure ml workspace name>\"     << Used in workspace.json settings filehe deployed completion and embedding models\n",
        "default_compute=\"<dedicated cluster name>\"                              # \"<enter dedicate compute cluster name>\"   << !! Note: only works with dedicate compute cluster\n",
        "                                                                        # \"serverless\"                              << !! Note: \"serverless\" and \"named\" compute instances are current causing failure in generate_meta_embedding step\n",
        "\n",
        "# Azure OpenAI settings\n",
        "aoai_connection_name = \"Default_AzureOpenAI\"                            # \"<default is Default_AzureOpenAI>\"        << Use the Azure OpenAI resource with t\n",
        "aoai_embedding_model_name = \"text-embedding-ada-002\"                    # \"<default to text-embedding-ada-002\"      << Recommendation is text-embedding-ada-002\n",
        "aoai_completion_model_name = \"gpt-35-turbo\"                             # \"<default to gpt-35-turbo>\"               << Recommendation is gpt-35-turbo\n",
        "\n",
        "# Set vector index asset name\n",
        "datastore_name = \"<enter the name of the Datastore>\"                    # \"<enter the name of the Datastore>\"       << The database registered in Data > Datastore to create embeddings\n",
        "datastore_scope = \"all\"                                                 # \"<enter the scope to be indexed>\"         << \"all\" = all tables, anything else need a list of tables/views \n",
        "data_asset_name = f\"{datastore_name}_{datastore_scope}_llm_index\"       # \"<enter the vector index suffix>\"         << The index to be created in Data > Data Asset"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689182662773
        }
      },
      "id": "f3b8ad4a-952d-4091-a5b7-7196e1e3c5f6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "If datastore_scope is not \"all\" then create a list of tables to be in the scope of the vector index"
      ],
=======
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ce2e8d-c46e-4ff1-b5a4-506ea9914503",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
<<<<<<< HEAD
      "id": "58ce2e8d-c46e-4ff1-b5a4-506ea9914503"
    },
    {
      "cell_type": "code",
=======
      "source": [
        "If datastore_scope is not \"all\" then create a list of tables to be in the scope of the vector index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59e95ca4-dbb6-4750-b192-2547fd0ccb18",
      "metadata": {
        "gather": {
          "logged": 1689182662829
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "database_tables = None\n",
        "\n",
        "if datastore_scope != \"all\":\n",
        "    tables = []\n",
        "    tables.append('[SalesLT].[Address]')\n",
        "    tables.append('[SalesLT].[Customer]')\n",
        "    tables.append('[SalesLT].[CustomerAddress]')\n",
        "    # tables.append('[SalesLT].[Product]')\n",
        "    # tables.append('[SalesLT].[ProductCategory]')\n",
        "    # tables.append('[SalesLT].[ProductDescription]')\n",
        "    # tables.append('[SalesLT].[ProductModel]')\n",
        "    # tables.append('[SalesLT].[ProductModelProductDescription]')\n",
        "    database_tables = str(tables)\n",
        "\n",
        "print(f\"Tables to Index: {database_tables}\")"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689182662829
        }
      },
      "id": "59e95ca4-dbb6-4750-b192-2547fd0ccb18"
=======
      ]
>>>>>>> c9d8d67 (Updates to sample code)
    },
    {
      "attachments": {},
      "cell_type": "markdown",
<<<<<<< HEAD
=======
      "id": "1a99955c",
      "metadata": {},
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "## Create client for AzureML Workspace\n",
        "\n",
        "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
        "\n"
<<<<<<< HEAD
      ],
      "metadata": {},
      "id": "1a99955c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a local `workspace.json` file used to create `MLClient`"
      ],
=======
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab43031-6c04-4b83-8eab-06bd06742951",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
<<<<<<< HEAD
      "id": "cab43031-6c04-4b83-8eab-06bd06742951"
    },
    {
      "cell_type": "code",
=======
      "source": [
        "Create a local `workspace.json` file used to create `MLClient`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b0a396d-a2e5-40a6-a8f4-643893f10b33",
      "metadata": {
        "gather": {
          "logged": 1689182662965
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "# Define the dictionary to be written as workspace JSON\n",
        "workspace_dict = {\n",
        "    \"subscription_id\": subscription_id,\n",
        "    \"resource_group\": resource_group_name,\n",
        "    \"workspace_name\": azure_ml_workspace_name\n",
        "}\n",
        "\n",
        "# Open the file and write the JSON data\n",
        "with open(\"workspace.json\", \"w\") as file:\n",
        "    json.dump(workspace_dict, file)\n",
        "\n",
        "# Open the file and load its contents\n",
        "with open(\"workspace.json\", \"r\") as file:\n",
        "    workspace_data = json.load(file)\n",
        "\n",
        "# print the workspace data for verification\n",
        "print(f\"Workspace JSON: {workspace_data}\")"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689182662965
        }
      },
      "id": "5b0a396d-a2e5-40a6-a8f4-643893f10b33"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get `credential` to create `MLClient`."
      ],
=======
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3b80ce-8f77-4e9c-adb3-2cc721b1978d",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
<<<<<<< HEAD
      "id": "fc3b80ce-8f77-4e9c-adb3-2cc721b1978d"
    },
    {
      "cell_type": "code",
=======
      "source": [
        "Get `credential` to create `MLClient`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58590635-d105-4de9-bac8-777e74235065",
      "metadata": {
        "gather": {
          "logged": 1689182664733
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "try:\n",
        "    print('Try DefaultAzureCredential creation')\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "    print('DefaultAzureCredential success')\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    print('Try EnvironmentCredential creation')\n",
<<<<<<< HEAD
        "    # Fall back to EnvironmentCredential in case DefaultAzureCredential not work\n",
=======
        "    # Fall back to EnvironmentCredential in case DefaultAzureCredential does not work\n",
>>>>>>> c9d8d67 (Updates to sample code)
        "    os.environ['AZURE_TENANT_ID'] = tenent_id\n",
        "    os.environ['AZURE_CLIENT_ID'] = application_client_id\n",
        "    os.environ['AZURE_CLIENT_SECRET'] = application_client_secret\n",
        "    credential = DefaultAzureCredential(exclude_managed_identity_credential=True)\n",
        "    credential.get_token(\"https://management.azure.com/.default\")"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689182664733
        }
      },
      "id": "58590635-d105-4de9-bac8-777e74235065"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using workspace JSON file and credential create `MLClient` to interact with AzureML"
      ],
      "metadata": {},
      "id": "1fb5c8f0"
    },
    {
      "cell_type": "code",
=======
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb5c8f0",
      "metadata": {},
      "source": [
        "Using workspace JSON file and credential create `MLClient` to interact with AzureML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb39686-ca94-4767-95ce-381e249f942d",
      "metadata": {
        "gather": {
          "logged": 1689182666559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "try:\n",
        "    ml_client = MLClient.from_config(credential=credential, path=\"workspace.json\")\n",
        "except Exception as ex:\n",
        "    raise Exception(\"Failed to create MLClient from config file. Please verify AzureML Workspace details and update Execution Variables above.\") from ex\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "print(ml_client)"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1689182666559
        }
      },
      "id": "cbb39686-ca94-4767-95ce-381e249f942d"
=======
      ]
>>>>>>> c9d8d67 (Updates to sample code)
    },
    {
      "attachments": {},
      "cell_type": "markdown",
<<<<<<< HEAD
=======
      "id": "30906d39",
      "metadata": {},
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "## Azure OpenAI\n",
        "\n",
        "We recommend using gpt-35-turbo model to get good quality QAs. [Follow these instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) to setup an Azure OpenAI Instance and deploy the model. Once you have the model deployed in AOAI you can specify your Model name and Deployment name below.\n",
        "\n",
        "We will use the automatically created `Default_AzureOpenAI` connection, change `aoai_connection_name` to use your own."
<<<<<<< HEAD
      ],
      "metadata": {},
      "id": "30906d39"
    },
    {
      "cell_type": "code",
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129ac0b7",
      "metadata": {
        "gather": {
          "logged": 1689182667206
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "from azureml.rag.utils.connections import get_connection_by_name_v2\n",
        "\n",
        "try:\n",
        "    # Get the Azure OpenAI Connection\n",
        "    aoai_connection = get_connection_by_name_v2(ws, aoai_connection_name)\n",
        "    # Get the Azure OpenAI connection id\n",
        "    aoai_connection_id = aoai_connection[\"id\"]\n",
        "    # Print Azure OpenAI connection info\n",
        "    print(f\"Azure OpenAI connection: {aoai_connection}\")\n",
        "    \n",
        "except Exception as ex:\n",
        "    print(f'Exception: {ex}')\n",
        "    print(f'Unable to create a connection to the Azure OpenAI resource named: {aoai_connection_name}')\n"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689182667206
        }
      },
      "id": "129ac0b7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **embedding** model has been deployed (recommendation is `text-embedding-ada-002`)\n",
        "\n",
        "This cell will fail if there is not deployment for the embeddings model, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a model with Azure OpenAI."
      ],
=======
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac0df32-83a0-4e13-ba94-bf5e00e812bc",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
<<<<<<< HEAD
      "id": "1ac0df32-83a0-4e13-ba94-bf5e00e812bc"
    },
    {
      "cell_type": "code",
=======
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **embedding** model has been deployed (recommendation is `text-embedding-ada-002`)\n",
        "\n",
        "This cell will fail if there is not deployment for the embeddings model, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a model with Azure OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c045de88",
      "metadata": {
        "gather": {
          "logged": 1689182667402
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "try:\n",
        "    aoai_embedding_deployment_name = infer_deployment(aoai_connection, aoai_embedding_model_name)\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is '{aoai_embedding_deployment_name}'\")\n",
        "except Exception as ex:\n",
        "    print(f\"Exception: {ex}\")\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is not found.\")\n",
        "    print(f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\")"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689182667402
        }
      },
      "id": "c045de88"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **completion** model has been deployed (recommendation is `gpt-35-turbo`)\n",
        "\n",
        "The following cell will fail if a **completion** model is not deployed, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a **completion** model with Azure OpenAI."
      ],
=======
      ]
    },
    {
      "cell_type": "markdown",
      "id": "450868d1-6deb-428b-81ad-8c2203da31bd",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
<<<<<<< HEAD
      "id": "450868d1-6deb-428b-81ad-8c2203da31bd"
    },
    {
      "cell_type": "code",
=======
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **completion** model has been deployed (recommendation is `gpt-35-turbo`)\n",
        "\n",
        "The following cell will fail if a **completion** model is not deployed, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a **completion** model with Azure OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e5cc13",
      "metadata": {
        "gather": {
          "logged": 1689182667467
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "try:\n",
        "    aoai_completion_deployment_name = infer_deployment(aoai_connection, aoai_completion_model_name)\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is '{aoai_completion_deployment_name}'\")\n",
        "except Exception as ex:\n",
        "    print(f\"Exception: {ex}\")\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is not found.\")\n",
        "    print(f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\")\n",
        "\n",
        "# Create LLM completion config in URI form which the AzureML embeddings components expect as input.\n",
        "llm_completion_config = f'{{\"type\":\"azure_open_ai\",\"model_name\":\"{aoai_completion_model_name}\",\"deployment_name\":\"{aoai_completion_deployment_name}\",\"temperature\":0,\"max_tokens\":\"1500\"}}'"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689182667467
        }
      },
      "id": "c1e5cc13"
=======
      ]
>>>>>>> c9d8d67 (Updates to sample code)
    },
    {
      "attachments": {},
      "cell_type": "markdown",
<<<<<<< HEAD
=======
      "id": "56878876",
      "metadata": {},
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "### Setup Pipeline\n",
        "\n",
        "The Components are published to a [Registry](https://learn.microsoft.com/azure/machine-learning/how-to-manage-registries?view=azureml-api-2&tabs=cli), `azureml`, which should have access to by default, it can be accessed from any Workspace.\n",
        "In the below cell we get the Component Definitions from the `azureml` registry."
<<<<<<< HEAD
      ],
      "metadata": {},
      "id": "56878876"
    },
    {
      "cell_type": "code",
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a3752a",
      "metadata": {
        "gather": {
          "logged": 1689182667820
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
        "\n",
        "db_copilot_component = ml_registry.components.get(\"llm_ingest_db_to_faiss\", label=\"latest\")\n",
        "\n",
        "print(db_copilot_component)"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689182667820
        }
      },
      "id": "e2a3752a"
    },
    {
      "cell_type": "code",
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209700d2",
      "metadata": {
        "gather": {
          "logged": 1689182668206
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "from azure.ai.ml.dsl import pipeline\n",
        "@pipeline(\n",
        "    name=f\"db_copilot_vector_pipeline_faiss\",\n",
        "    default_compute=default_compute\n",
        ")\n",
        "def db_copilot_vector_pipeline_faiss(\n",
        "    aoai_connection: str,\n",
        "    db_datastore: str,\n",
        "    embeddings_model: str,\n",
        "    chat_aoai_deployment_name: str,\n",
        "    embedding_aoai_deployment_name: str,\n",
        "    mlindex_dataset_name: str,\n",
        "    selected_tables: str = None,\n",
        "    max_sampling_rows: int = 3,\n",
        "):\n",
        "    db_copilot_component(\n",
        "        db_datastore=db_datastore,\n",
        "        embeddings_model=embeddings_model,\n",
        "        chat_aoai_deployment_name=chat_aoai_deployment_name,\n",
        "        embedding_aoai_deployment_name=embedding_aoai_deployment_name,\n",
        "        embeddings_dataset_name=mlindex_dataset_name,\n",
        "        embedding_connection=aoai_connection,\n",
        "        llm_connection=aoai_connection,\n",
        "        selected_tables=selected_tables,\n",
        "        max_sampling_rows=max_sampling_rows,\n",
        "    )\n",
        "    return {}\n"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689182668206
        }
      },
      "id": "209700d2"
    },
    {
      "cell_type": "code",
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6682ea80",
      "metadata": {
        "gather": {
          "logged": 1689182668337
        }
      },
      "outputs": [],
>>>>>>> c9d8d67 (Updates to sample code)
      "source": [
        "# Create pipeline job\n",
        "pipeline_job = db_copilot_vector_pipeline_faiss(\n",
        "    aoai_connection=aoai_connection_id,\n",
        "    db_datastore=f\"azureml://datastores/{datastore_name}\",\n",
        "    embeddings_model=f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_embedding_model_name}\",\n",
        "    chat_aoai_deployment_name=aoai_completion_deployment_name,\n",
        "    embedding_aoai_deployment_name=aoai_embedding_deployment_name,\n",
        "    mlindex_dataset_name=data_asset_name,\n",
        "    selected_tables=\"[\\\"[SalesLT].[Product]\\\"]\",\n",
        "    max_sampling_rows=3,\n",
        ")"
<<<<<<< HEAD
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1689182668337
        }
      },
      "id": "6682ea80"
    },
    {
      "cell_type": "code",
      "source": [
        "# These are added so that in progress index generations can be listed in UI, this tagging is done automatically by UI.\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = data_asset_name\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Database\""
      ],
      "outputs": [],
      "execution_count": null,
=======
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00fd418",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "gather": {
          "logged": 1689182668399
        }
      },
<<<<<<< HEAD
      "id": "b00fd418"
    },
    {
      "cell_type": "code",
      "source": [
        "running_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=str.lower(f\"{datastore_name}_{datastore_scope}_dbcopilot_pipeline\")\n",
        ")\n",
        "running_pipeline_job"
      ],
      "outputs": [],
      "execution_count": null,
=======
      "outputs": [],
      "source": [
        "# These are added so that in progress index generations can be listed in UI, this tagging is done automatically by UI.\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = data_asset_name\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Database\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d9b2be",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "gather": {
          "logged": 1689182670964
        }
      },
<<<<<<< HEAD
      "id": "52d9b2be"
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.jobs.stream(running_pipeline_job.name)"
      ],
      "outputs": [],
      "execution_count": null,
=======
      "outputs": [],
      "source": [
        "running_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=str.lower(f\"{datastore_name}_{datastore_scope}_dbcopilot_pipeline\")\n",
        ")\n",
        "running_pipeline_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c71f975c",
>>>>>>> c9d8d67 (Updates to sample code)
      "metadata": {
        "gather": {
          "logged": 1689182301371
        }
      },
<<<<<<< HEAD
      "id": "c71f975c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use DBCopilot with Promptflow\n",
        "After the pipeline complete, it will create a promptflow which could be used to chat with the db."
      ],
      "metadata": {},
      "id": "d098fccd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
=======
      "outputs": [],
      "source": [
        "ml_client.jobs.stream(running_pipeline_job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d098fccd",
      "metadata": {},
      "source": [
        "## Use DBCopilot with Promptflow\n",
        "After the pipeline complete, it will create a promptflow which could be used to chat with the db."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
>>>>>>> c9d8d67 (Updates to sample code)
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
<<<<<<< HEAD
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
=======
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
>>>>>>> c9d8d67 (Updates to sample code)
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
<<<<<<< HEAD
      }
    },
    "kernel_info": {
      "name": "python3"
    },
=======
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
>>>>>>> c9d8d67 (Updates to sample code)
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
<<<<<<< HEAD
}
=======
}
>>>>>>> c9d8d67 (Updates to sample code)
