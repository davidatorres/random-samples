{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28b26c69",
      "metadata": {},
      "source": [
        "# Create a FAISS based Vector Index for DBCopilot with AzureML\n",
        "We'll walk through setting up an AzureML Pipeline which grounding a Database into a LangChain-compatible FAISS Vector Index and create the Prompt flow to consume this index to serve as a DBCopilot chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c3eb0084",
      "metadata": {},
      "outputs": [],
      "source": [
        "# create an conda environment with the exported file AMLenv.conda which should be in the same project directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "345e6aa4",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# If AMLenv.conda is not available, use the following commands to install the required packages in the python/conda environment\n",
        "# \n",
        "# %pip install azureml-core\n",
        "# %pip install azure-ai-ml\n",
        "# %pip install -U 'azureml-rag[faiss]>=0.1.11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "038912d8",
      "metadata": {
        "gather": {
          "logged": 1689182662643
        }
      },
      "outputs": [],
      "source": [
        "# If `import win32file` fails with a DLL error then run the following and restart kernel:\n",
        "# %pip uninstall -y pywin32\n",
        "# %conda install -y --force-reinstall pywin32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "734d8c1a-9bc2-4957-9251-c529e3f1b826",
      "metadata": {
        "gather": {
          "logged": 1689182662703
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# System imports\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ebd2ec7e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\davidtorres\\Code\\GitHub-dat\\random-samples\\AzureML\\DBCopilot\\.env\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# retrieve and print environment variables\n",
        "#\n",
        "# Load environment variables from an .env file\n",
        "# this is a way to keep sensitive information out of the codebase\n",
        "# you can use the .env.sample file as a template for the .env file\n",
        "#  - copy the .env.sample file to .env\n",
        "#  - fill in the values for your environment\n",
        "#  - make sure .env and it's realative path are in .gitignore\n",
        "#\n",
        "# The following code allows for .env file to be in same directory as script\n",
        "# or you can specify the path relative to the notebook to the .env file\n",
        "# \n",
        "from os.path import join\n",
        "from dotenv import load_dotenv\n",
        "dotenv_path = join(os.getcwd(), '.env')\n",
        "print(dotenv_path)\n",
        "load_dotenv(dotenv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f3b8ad4a-952d-4091-a5b7-7196e1e3c5f6",
      "metadata": {
        "gather": {
          "logged": 1689182662773
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Execution Variables\n",
        "\n",
        "# Tenent and Application Id settings\n",
        "tenant_id = os.getenv('TENANT_ID')                                      # \"<enter the tenent id>\"                   << Used for EnvironmentCredential\n",
        "application_client_id = os.getenv('CLIENT_ID')                          # \"<enter application client id>\"           << Used for EnvironmentCredential\n",
        "application_client_secret = os.getenv('CLIENT_SECRET')                  # \"<enter application client secret>\"       << Used for EnvironmentCredential\n",
        "\n",
        "# Azure Workspace settings\n",
        "subscription_id = os.getenv('SUBSCRIPTION_ID')                          # \"<enter the subscription id>\"             << Used in workspace.json settings file\n",
        "resource_group_name = os.getenv('RESOURCE_GROUP')                       # \"<enter the resource group name>\"         << Used in workspace.json settings file\n",
        "workspace_name = os.getenv('WORKSPACE_NAME')                            # \"<enter the azure ml workspace name>\"     << Used in workspace.json settings file\n",
        "default_compute=os.getenv('CLUSTER_NAME')                               # \"<enter dedicate compute cluster name>\"   << !! Only works with dedicate compute cluster\n",
        "                                                                        # \"serverless\"                              << !! \"serverless\" and \"named\" compute instances are \n",
        "                                                                        #  NOTE >>>>                                << !! currently causing failure in generate_meta_embedding step\n",
        "\n",
        "# Azure OpenAI settings\n",
        "aoai_connection_name = \"Default_AzureOpenAI\"                            # \"<default is Default_AzureOpenAI>\"        << Use the Azure OpenAI resource connection name\n",
        "aoai_embedding_model_name = \"text-embedding-ada-002\"                    # \"<default to text-embedding-ada-002\"      << Recommendation is text-embedding-ada-002\n",
        "aoai_completion_model_name = \"gpt-35-turbo\"                             # \"<default to gpt-35-turbo (0301)>\"        << Recommendation is gpt-35-turbo (0301)\n",
        "                                                                        # NOTE >>>>                                 << !! gpt-35-turbo (0613) and gpt-35-turbo-16 are not support for completions\n",
        "\n",
        "# Set vector index asset name\n",
        "datastore_name = os.getenv('DATA_STORE_NAME')                           # \"<enter the name of the Datastore>\"       << The database registered in Data > Datastore to create embeddings\n",
        "datastore_scope = \"array\"                                               # \"<enter the scope to be indexed>\"         << \"all\" = all tables, anything else need a list of tables/views \n",
        "data_asset_name = f\"{datastore_name}_{datastore_scope}_llm_index\"       # \"<enter the vector index suffix>\"         << The index to be created in Data > Data Asset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ce2e8d-c46e-4ff1-b5a4-506ea9914503",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "If datastore_scope is not \"all\" then create a list of tables to be in the scope of the vector index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "59e95ca4-dbb6-4750-b192-2547fd0ccb18",
      "metadata": {
        "gather": {
          "logged": 1689182662829
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tables to Index: all\n"
          ]
        }
      ],
      "source": [
        "if datastore_scope != \"all\":\n",
        "    tables = []\n",
        "    tables.append('[HumanResources].[Department]')\n",
        "    tables.append('[HumanResources].[Employee]')\n",
        "    tables.append('[HumanResources].[EmployeeDepartmentHistory]')\n",
        "    tables.append('[HumanResources].[EmployeePayHistory]')\n",
        "    tables.append('[HumanResources].[JobCandidate]')\n",
        "    tables.append('[HumanResources].[Shift]')\n",
        "    tables.append('[Person].[Address]')\n",
        "    tables.append('[Person].[AddressType]')\n",
        "    tables.append('[Person].[BusinessEntity]')\n",
        "    tables.append('[Person].[BusinessEntityAddress]')\n",
        "    tables.append('[Person].[BusinessEntityContact]')\n",
        "    tables.append('[Person].[ContactType]')\n",
        "    tables.append('[Person].[CountryRegion]')\n",
        "    tables.append('[Person].[EmailAddress]')\n",
        "    tables.append('[Person].[Password]')\n",
        "    tables.append('[Person].[Person]')\n",
        "    tables.append('[Person].[PersonPhone]')\n",
        "    tables.append('[Person].[PhoneNumberType]')\n",
        "    tables.append('[Person].[StateProvince]')\n",
        "    tables.append('[Production].[BillOfMaterials]')\n",
        "    tables.append('[Production].[Culture]')\n",
        "    tables.append('[Production].[Document]')\n",
        "    tables.append('[Production].[Illustration]')\n",
        "    tables.append('[Production].[Location]')\n",
        "    tables.append('[Production].[Product]')\n",
        "    tables.append('[Production].[ProductCategory]')\n",
        "    tables.append('[Production].[ProductCostHistory]')\n",
        "    tables.append('[Production].[ProductDescription]')\n",
        "    tables.append('[Production].[ProductDocument]')\n",
        "    tables.append('[Production].[ProductInventory]')\n",
        "    tables.append('[Production].[ProductListPriceHistory]')\n",
        "    tables.append('[Production].[ProductModel]')\n",
        "    tables.append('[Production].[ProductModelIllustration]')\n",
        "    tables.append('[Production].[ProductModelProductDescriptionCulture]')\n",
        "    tables.append('[Production].[ProductPhoto]')\n",
        "    tables.append('[Production].[ProductProductPhoto]')\n",
        "    tables.append('[Production].[ProductReview]')\n",
        "    tables.append('[Production].[ProductSubcategory]')\n",
        "    tables.append('[Production].[ScrapReason]')\n",
        "    tables.append('[Production].[TransactionHistory]')\n",
        "    tables.append('[Production].[TransactionHistoryArchive]')\n",
        "    tables.append('[Production].[UnitMeasure]')\n",
        "    tables.append('[Production].[WorkOrder]')\n",
        "    tables.append('[Production].[WorkOrderRouting]')\n",
        "    tables.append('[Purchasing].[ProductVendor]')\n",
        "    tables.append('[Purchasing].[PurchaseOrderDetail]')\n",
        "    tables.append('[Purchasing].[PurchaseOrderHeader]')\n",
        "    tables.append('[Purchasing].[ShipMethod]')\n",
        "    tables.append('[Purchasing].[Vendor]')\n",
        "    tables.append('[Sales].[CountryRegionCurrency]')\n",
        "    tables.append('[Sales].[CreditCard]')\n",
        "    tables.append('[Sales].[Currency]')\n",
        "    tables.append('[Sales].[CurrencyRate]')\n",
        "    tables.append('[Sales].[Customer]')\n",
        "    tables.append('[Sales].[PersonCreditCard]')\n",
        "    tables.append('[Sales].[SalesOrderDetail]')\n",
        "    tables.append('[Sales].[SalesOrderHeader]')\n",
        "    tables.append('[Sales].[SalesOrderHeaderSalesReason]')\n",
        "    tables.append('[Sales].[SalesPerson]')\n",
        "    tables.append('[Sales].[SalesPersonQuotaHistory]')\n",
        "    tables.append('[Sales].[SalesReason]')\n",
        "    tables.append('[Sales].[SalesTaxRate]')\n",
        "    tables.append('[Sales].[SalesTerritory]')\n",
        "    tables.append('[Sales].[SalesTerritoryHistory]')\n",
        "    tables.append('[Sales].[ShoppingCartItem]')\n",
        "    tables.append('[Sales].[SpecialOffer]')\n",
        "    tables.append('[Sales].[SpecialOfferProduct]')\n",
        "    tables.append('[Sales].[Store]')\n",
        "    # Convert array of table names to string\n",
        "    selected_tables = str(tables).replace(\"'\", '\\\"')\n",
        "else:\n",
        "    selected_tables = 'all'\n",
        "\n",
        "print(f\"Tables to Index: {selected_tables}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1a99955c",
      "metadata": {},
      "source": [
        "## Create client for AzureML Workspace\n",
        "\n",
        "The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3b80ce-8f77-4e9c-adb3-2cc721b1978d",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Get `credential` to create `MLClient`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "58590635-d105-4de9-bac8-777e74235065",
      "metadata": {
        "gather": {
          "logged": 1689182664733
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AccessToken(token='eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6Ii1LSTNROW5OUjdiUm9meG1lWm9YcWJIWkdldyIsImtpZCI6Ii1LSTNROW5OUjdiUm9meG1lWm9YcWJIWkdldyJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuYXp1cmUuY29tIiwiaXNzIjoiaHR0cHM6Ly9zdHMud2luZG93cy5uZXQvNzJmOTg4YmYtODZmMS00MWFmLTkxYWItMmQ3Y2QwMTFkYjQ3LyIsImlhdCI6MTY5NDQ2NTE4OCwibmJmIjoxNjk0NDY1MTg4LCJleHAiOjE2OTQ1NTE4ODgsImFpbyI6IkUyRmdZUGlhYnRPc0pHcFRMTWcvUWNSUTRPUlBBQT09IiwiYXBwaWQiOiJiZDhlNDU3Ni0zYjA2LTQ5MTgtYmU3ZC0wYjZhODE3NTA5ZWYiLCJhcHBpZGFjciI6IjEiLCJpZHAiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC83MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDcvIiwiaWR0eXAiOiJhcHAiLCJvaWQiOiI4Y2Q2OWM1Yy04YzU4LTQ5MTgtOTk2Zi1mOTI0ZmFlN2M4NmMiLCJyaCI6IjAuQVJvQXY0ajVjdkdHcjBHUnF5MTgwQkhiUjBaSWYza0F1dGRQdWtQYXdmajJNQk1hQUFBLiIsInN1YiI6IjhjZDY5YzVjLThjNTgtNDkxOC05OTZmLWY5MjRmYWU3Yzg2YyIsInRpZCI6IjcyZjk4OGJmLTg2ZjEtNDFhZi05MWFiLTJkN2NkMDExZGI0NyIsInV0aSI6IldKOEpacDVZSFUyNnNsTXpLM2pJQUEiLCJ2ZXIiOiIxLjAiLCJ4bXNfdGNkdCI6MTI4OTI0MTU0N30.LcazQQbSGkfeIzW_XptWj_YSDoqZlC7bWmRQ_9z99faRG5qgAp-PMibKfsgYktjpbB2Ay0wDSXtbIOy-8qGqpMGw9mJYyaHxX9yZ4Spj4r8y638V9uCqKzhpo54qDV2R80VxTdO4wxsbKako95PV6ukcJrJu6bDrDU3Z8XPmyRjKSP70dpvtsEAzutLHX5Lhu-VOtphj-zYcHg6x6_wpu1zq5OVruiNwWvZ0Fgp0T6_u6eiRVtXtD1G6SbpEEltOybz3h3kEBFHKFSVLrvfowyK3ZnGZP-SsQW7PwY2Ugorv0lJQ6jprDieddoclhWOyP3lEBR1m_4Nt10oNwTKBEw', expires_on=1694551887)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azure.identity import DefaultAzureCredential, ClientSecretCredential, EnvironmentCredential, AzureCliCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Create ClientSecretCredential as default credential\n",
        "# Service Principal (Application Client) must have Contributor role on the Azure ML Workspace \n",
        "try:\n",
        "    ## Set expected environment variables\n",
        "    os.environ['AZURE_TENANT_ID'] = tenant_id\n",
        "    os.environ['AZURE_CLIENT_ID'] = application_client_id\n",
        "    os.environ['AZURE_CLIENT_SECRET'] = application_client_secret\n",
        "    os.environ['AZURE_AUTHORITY_HOST'] = 'https://login.microsoftonline.com'\n",
        "    credential = ClientSecretCredential(tenant_id=tenant_id, client_id=application_client_id, client_secret=application_client_secret)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    print('Try DefaultAzureCredential creation')\n",
        "    # Fall back to DefaultAzureCredential, if ClientSecretCredential does not work\n",
        "    # DefaultAzureCredential will look for credientials sequentially see docs at\n",
        "    # https://learn.microsoft.com/en-us/dotnet/api/azure.identity.defaultazurecredential\n",
        "    try:\n",
        "        credential = DefaultAzureCredential()\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "\n",
        "credential.get_token(\"https://management.azure.com/.default\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb5c8f0",
      "metadata": {},
      "source": [
        "Create `MLClient` to interact with AzureML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "cbb39686-ca94-4767-95ce-381e249f942d",
      "metadata": {
        "gather": {
          "logged": 1689182666559
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLClient(credential=<azure.identity._credentials.client_secret.ClientSecretCredential object at 0x0000022D19261F90>,\n",
            "         subscription_id=8878a446-3d3e-44c2-bae5-09fd1d17e6d6,\n",
            "         resource_group_name=common-ai-dev,\n",
            "         workspace_name=common-ai-dev-ml)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    ml_client= MLClient(credential=credential, subscription_id=subscription_id, resource_group_name=resource_group_name, workspace_name=workspace_name)\n",
        "except Exception as ex:\n",
        "    raise Exception(\"Failed to create MLClient from config file. Please verify AzureML Workspace details and update Execution Variables above.\") from ex\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group=ml_client.resource_group_name,\n",
        "    workspace_name=ml_client.workspace_name,\n",
        ")\n",
        "print(ml_client)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "30906d39",
      "metadata": {},
      "source": [
        "## Azure OpenAI\n",
        "\n",
        "We recommend using gpt-35-turbo model to get good quality QAs. [Follow these instructions](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) to setup an Azure OpenAI Instance and deploy the model. Once you have the model deployed in AOAI you can specify your Model name and Deployment name below.\n",
        "\n",
        "We will use the automatically created `Default_AzureOpenAI` connection, change `aoai_connection_name` to use your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "129ac0b7",
      "metadata": {
        "gather": {
          "logged": 1689182667206
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure OpenAI connection: \n",
            "{\n",
            "    \"tags\": null,\n",
            "    \"location\": null,\n",
            "    \"id\": \"/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourceGroups/common-ai-dev/providers/Microsoft.MachineLearningServices/workspaces/common-ai-dev-ml/connections/Default_AzureOpenAI\",\n",
            "    \"name\": \"Default_AzureOpenAI\",\n",
            "    \"type\": \"Microsoft.MachineLearningServices/workspaces/connections\",\n",
            "    \"properties\": {\n",
            "        \"authType\": \"ApiKey\",\n",
            "        \"credentials\": {\n",
            "            \"key\": \"f7f4b78604f04f1b9851c94af756adde\"\n",
            "        },\n",
            "        \"category\": \"AzureOpenAI\",\n",
            "        \"expiryTime\": null,\n",
            "        \"target\": \"https://common-ai-dev-ml-aoai.openai.azure.com/\",\n",
            "        \"createdByWorkspaceArmId\": null,\n",
            "        \"isSharedToAll\": true,\n",
            "        \"sharedUserList\": [],\n",
            "        \"metadata\": {\n",
            "            \"ApiVersion\": \"2023-03-15-preview\",\n",
            "            \"ApiType\": \"Azure\",\n",
            "            \"ProvisioningState\": \"Succeeded\",\n",
            "            \"ResourceId\": \"/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourceGroups/common-ai-dev/providers/Microsoft.CognitiveServices/accounts/common-ai-dev-ml-aoai\",\n",
            "            \"ProxyResourceId\": \"/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourceGroups/common-ai-dev/providers/Microsoft.MachineLearningServices/workspaces/common-ai-dev-ml/oaiaccounts/id_ffd23124e94449658eafa39a2fd31134\"\n",
            "        }\n",
            "    },\n",
            "    \"systemData\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from azureml.rag.utils.connections import get_connection_by_name_v2\n",
        "\n",
        "try:\n",
        "    # Get the Azure OpenAI Connection\n",
        "    aoai_connection = get_connection_by_name_v2(ws, aoai_connection_name)\n",
        "    # Get the Azure OpenAI connection id\n",
        "    aoai_connection_id = aoai_connection[\"id\"]\n",
        "    # Print Azure OpenAI connection info\n",
        "    print(f\"Azure OpenAI connection: \\n{json.dumps(aoai_connection, indent=4)}\")\n",
        "    \n",
        "except Exception as ex:\n",
        "    print(f'Exception: {ex}')\n",
        "    print(f'Unable to create a connection to the Azure OpenAI resource named: {aoai_connection_name}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ac0df32-83a0-4e13-ba94-bf5e00e812bc",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **embedding** model has been deployed (recommendation is `text-embedding-ada-002`)\n",
        "\n",
        "This cell will fail if there is not deployment for the embeddings model, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a model with Azure OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "c045de88",
      "metadata": {
        "gather": {
          "logged": 1689182667402
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deployment name in AOAI workspace for model 'text-embedding-ada-002' is 'text-embedding-ada-002'\n"
          ]
        }
      ],
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "try:\n",
        "    aoai_embedding_deployment_name = infer_deployment(aoai_connection, aoai_embedding_model_name)\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is '{aoai_embedding_deployment_name}'\")\n",
        "except Exception as ex:\n",
        "    print(f\"Exception: {ex}\")\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_embedding_model_name}' is not found.\")\n",
        "    print(f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "450868d1-6deb-428b-81ad-8c2203da31bd",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Now that the Workspace has a connection to Azure Open AI ensure the **completion** model has been deployed (recommendation is `gpt-35-turbo`)\n",
        "\n",
        "The following cell will fail if a **completion** model is not deployed, [follow these instructions](https://learn.microsoft.com/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#deploy-a-model) to deploy a **completion** model with Azure OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c1e5cc13",
      "metadata": {
        "gather": {
          "logged": 1689182667467
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deployment name in AOAI workspace for model 'gpt-35-turbo' is 'gpt-35-turbo'\n"
          ]
        }
      ],
      "source": [
        "from azureml.rag.utils.deployment import infer_deployment\n",
        "\n",
        "try:\n",
        "    aoai_completion_deployment_name = infer_deployment(aoai_connection, aoai_completion_model_name)\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is '{aoai_completion_deployment_name}'\")\n",
        "except Exception as ex:\n",
        "    print(f\"Exception: {ex}\")\n",
        "    print(f\"Deployment name in AOAI workspace for model '{aoai_completion_model_name}' is not found.\")\n",
        "    print(f\"Please create a deployment for this model by following the deploy instructions on the resource page for '{aoai_connection['properties']['target']}' in Azure Portal.\")\n",
        "\n",
        "# Create LLM completion config in URI form which the AzureML embeddings components expect as input.\n",
        "llm_completion_config = f'{{\"type\":\"azure_open_ai\",\"model_name\":\"{aoai_completion_model_name}\",\"deployment_name\":\"{aoai_completion_deployment_name}\",\"temperature\":0,\"max_tokens\":\"1500\"}}'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "56878876",
      "metadata": {},
      "source": [
        "### Setup Pipeline Job\n",
        "\n",
        "The Components are published to a [Registry](https://learn.microsoft.com/azure/machine-learning/how-to-manage-registries?view=azureml-api-2&tabs=cli), `azureml`, which should have access to by default, it can be accessed from any Workspace.\n",
        "In the below cell we get the Component Definitions from the `azureml` registry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e2a3752a",
      "metadata": {
        "gather": {
          "logged": 1689182667820
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "$schema: https://azuremlschemas.azureedge.net/latest/pipelineComponent.schema.json\n",
            "name: llm_ingest_db_to_faiss\n",
            "version: 0.0.21\n",
            "display_name: LLM - SQL Datastore to FAISS Pipeline\n",
            "description: Single job pipeline to chunk data from AzureML sql data store, and create\n",
            "  FAISS embeddings index\n",
            "type: pipeline\n",
            "inputs:\n",
            "  db_datastore:\n",
            "    type: string\n",
            "    optional: false\n",
            "    description: database datastore uri in the format of 'azureml://datastores/{datastore_name}'\n",
            "  embeddings_model:\n",
            "    type: string\n",
            "    optional: false\n",
            "    description: The model used to generate embeddings. 'azure_open_ai://endpoint/{endpoint_name}/deployment/{deployment_name}/model/{model_name}'\n",
            "  chat_aoai_deployment_name:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: The name of the chat AOAI deployment\n",
            "  embedding_aoai_deployment_name:\n",
            "    type: string\n",
            "    optional: false\n",
            "    description: The name of the embedding AOAI deployment\n",
            "  embeddings_dataset_name:\n",
            "    type: string\n",
            "    optional: false\n",
            "    description: The name of the faiss index\n",
            "  max_tables:\n",
            "    type: integer\n",
            "    optional: true\n",
            "  max_columns:\n",
            "    type: integer\n",
            "    optional: true\n",
            "  max_rows:\n",
            "    type: integer\n",
            "    optional: true\n",
            "  max_sampling_rows:\n",
            "    type: integer\n",
            "    optional: true\n",
            "  max_text_length:\n",
            "    type: integer\n",
            "    optional: true\n",
            "  selected_tables:\n",
            "    type: string\n",
            "    optional: true\n",
            "  column_settings:\n",
            "    type: string\n",
            "    optional: true\n",
            "  llm_config:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: The name of the llm config\n",
            "  serverless_instance_count:\n",
            "    type: integer\n",
            "    optional: true\n",
            "    default: '1'\n",
            "  serverless_instance_type:\n",
            "    type: string\n",
            "    optional: true\n",
            "    default: Standard_DS3_v2\n",
            "  embedding_connection:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: Azure OpenAI workspace connection ARM ID for embeddings\n",
            "  llm_connection:\n",
            "    type: string\n",
            "    optional: true\n",
            "    description: Azure OpenAI workspace connection ARM ID for LLM\n",
            "outputs:\n",
            "  grounding_index:\n",
            "    type: uri_folder\n",
            "  db_context:\n",
            "    type: uri_folder\n",
            "id: azureml://registries/azureml/components/llm_ingest_db_to_faiss/versions/0.0.21\n",
            "tags:\n",
            "  Preview: ''\n",
            "is_deterministic: false\n",
            "creation_context:\n",
            "  created_at: '2023-09-05T17:05:27.898926+00:00'\n",
            "  created_by: Microsoft\n",
            "  created_by_type: User\n",
            "  last_modified_at: '2023-09-05T17:05:27.898926+00:00'\n",
            "  last_modified_by: Microsoft\n",
            "  last_modified_by_type: User\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ml_registry = MLClient(credential=credential, registry_name=\"azureml\")\n",
        "\n",
        "db_copilot_component = ml_registry.components.get(\"llm_ingest_db_to_faiss\", label=\"latest\")\n",
        "\n",
        "print(db_copilot_component)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "209700d2",
      "metadata": {
        "gather": {
          "logged": 1689182668206
        }
      },
      "outputs": [],
      "source": [
        "# Create the pipeline\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "@pipeline(\n",
        "    name=f\"db_copilot_vector_pipeline_faiss\",\n",
        "    default_compute=default_compute\n",
        ")\n",
        "def db_copilot_vector_pipeline_faiss(\n",
        "    aoai_connection: str,\n",
        "    db_datastore: str,\n",
        "    embeddings_model: str,\n",
        "    chat_aoai_deployment_name: str,\n",
        "    embedding_aoai_deployment_name: str,\n",
        "    mlindex_dataset_name: str,\n",
        "    selected_tables: str = None,\n",
        "    max_sampling_rows: int = 3,\n",
        "):\n",
        "    db_copilot_component(\n",
        "        db_datastore=db_datastore,\n",
        "        embeddings_model=embeddings_model,\n",
        "        chat_aoai_deployment_name=chat_aoai_deployment_name,\n",
        "        embedding_aoai_deployment_name=embedding_aoai_deployment_name,\n",
        "        embeddings_dataset_name=mlindex_dataset_name,\n",
        "        embedding_connection=aoai_connection,\n",
        "        llm_connection=aoai_connection,\n",
        "        selected_tables=selected_tables,\n",
        "        max_sampling_rows=max_sampling_rows,\n",
        "    )\n",
        "    return {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6682ea80",
      "metadata": {
        "gather": {
          "logged": 1689182668337
        }
      },
      "outputs": [],
      "source": [
        "# Create pipeline job\n",
        "pipeline_job = db_copilot_vector_pipeline_faiss(\n",
        "    aoai_connection=aoai_connection_id,\n",
        "    db_datastore=f\"azureml://datastores/{datastore_name}\",\n",
        "    embeddings_model=f\"azure_open_ai://deployment/{aoai_embedding_deployment_name}/model/{aoai_embedding_model_name}\",\n",
        "    chat_aoai_deployment_name=aoai_completion_deployment_name,\n",
        "    embedding_aoai_deployment_name=aoai_embedding_deployment_name,\n",
        "    mlindex_dataset_name=data_asset_name,\n",
        "    selected_tables=selected_tables,\n",
        "    max_sampling_rows=3,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b00fd418",
      "metadata": {
        "gather": {
          "logged": 1689182668399
        }
      },
      "outputs": [],
      "source": [
        "# These are added so that in progress index generations can be listed in UI, this tagging is done automatically by UI.\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetName\"] = data_asset_name\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetKind\"] = \"faiss\"\n",
        "pipeline_job.properties[\"azureml.mlIndexAssetSource\"] = \"Database\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "52d9b2be",
      "metadata": {
        "gather": {
          "logged": 1689182670964
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>adventureworks2022_all_dbcopilot_pipeline</td><td>bright_cumin_384gpfjhy6</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/bright_cumin_384gpfjhy6?wsid=/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourcegroups/common-ai-dev/workspaces/common-ai-dev-ml&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "PipelineJob({'inputs': {'aoai_connection': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92D8A0>, 'db_datastore': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92DF30>, 'embeddings_model': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92DF90>, 'chat_aoai_deployment_name': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92E890>, 'embedding_aoai_deployment_name': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92E860>, 'mlindex_dataset_name': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92D4E0>, 'selected_tables': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92C610>, 'max_sampling_rows': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000022D1B92C370>}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\davidtorres\\\\Code\\\\GitHub-dat\\\\random-samples\\\\AzureML\\\\DBCopilot', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000022D1B92C7C0>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'db_copilot_vector_pipeline_faiss', 'is_deterministic': None, 'inputs': {'aoai_connection': {}, 'db_datastore': {}, 'embeddings_model': {}, 'chat_aoai_deployment_name': {}, 'embedding_aoai_deployment_name': {}, 'mlindex_dataset_name': {}, 'selected_tables': {}, 'max_sampling_rows': {}}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'llm_ingest_db_to_faiss': Pipeline({'init': False, 'name': 'llm_ingest_db_to_faiss', 'type': 'pipeline', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\davidtorres\\\\Code\\\\GitHub-dat\\\\random-samples\\\\AzureML\\\\DBCopilot', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000022D1B902DD0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'db_datastore': '${{parent.inputs.db_datastore}}', 'embeddings_model': '${{parent.inputs.embeddings_model}}', 'chat_aoai_deployment_name': '${{parent.inputs.chat_aoai_deployment_name}}', 'embedding_aoai_deployment_name': '${{parent.inputs.embedding_aoai_deployment_name}}', 'embeddings_dataset_name': '${{parent.inputs.mlindex_dataset_name}}', 'max_sampling_rows': '${{parent.inputs.max_sampling_rows}}', 'selected_tables': '${{parent.inputs.selected_tables}}', 'embedding_connection': '${{parent.inputs.aoai_connection}}', 'llm_connection': '${{parent.inputs.aoai_connection}}'}, 'job_outputs': {}, 'inputs': {'db_datastore': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92DB70>, 'embeddings_model': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D870>, 'chat_aoai_deployment_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D030>, 'embedding_aoai_deployment_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D090>, 'embeddings_dataset_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D8D0>, 'max_sampling_rows': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D2D0>, 'selected_tables': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D5D0>, 'embedding_connection': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D600>, 'llm_connection': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000022D1B92D5A0>}, 'outputs': {}, 'component': 'azureml://registries/azureml/components/llm_ingest_db_to_faiss/versions/0.0.21', 'referenced_control_flow_node_instance_id': None, 'kwargs': {}, 'instance_id': '7916758f-1ad3-43b6-b6d8-1aeeefd3e33b', 'source': 'REMOTE.REGISTRY', 'validate_required_input_not_provided': True, 'settings': None})}, 'job_types': {'pipeline': 1}, 'job_sources': {'REMOTE.REGISTRY': 1}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'bright_cumin_384gpfjhy6', 'description': None, 'tags': {}, 'properties': {'azureml.mlIndexAssetName': 'adventureworks2022_all_llm_index', 'azureml.mlIndexAssetKind': 'faiss', 'azureml.mlIndexAssetSource': 'Database', 'mlflow.source.git.repoURL': 'https://github.com/davidatorres/random-samples', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '4c7b8f8013d780beb69076bdd24a82c8fe7e0054', 'azureml.git.dirty': 'True', 'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{\"aoai_connection\":\"/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourceGroups/common-ai-dev/providers/Microsoft.MachineLearningServices/workspaces/common-ai-dev-ml/connections/Default_AzureOpenAI\",\"db_datastore\":\"azureml://datastores/adventureworks2022\",\"embeddings_model\":\"azure_open_ai://deployment/text-embedding-ada-002/model/text-embedding-ada-002\",\"chat_aoai_deployment_name\":\"gpt-35-turbo\",\"embedding_aoai_deployment_name\":\"text-embedding-ada-002\",\"mlindex_dataset_name\":\"adventureworks2022_all_llm_index\",\"selected_tables\":\"all\",\"max_sampling_rows\":\"3\"}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'common-ai-dev-ml-cluster', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourceGroups/common-ai-dev/providers/Microsoft.MachineLearningServices/workspaces/common-ai-dev-ml/jobs/bright_cumin_384gpfjhy6', 'Resource__source_path': None, 'base_path': 'c:\\\\Users\\\\davidtorres\\\\Code\\\\GitHub-dat\\\\random-samples\\\\AzureML\\\\DBCopilot', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000022D1B92D960>, 'serialize': <msrest.serialization.Serializer object at 0x0000022D1B92C700>, 'display_name': 'db_copilot_vector_pipeline_faiss', 'experiment_name': 'adventureworks2022_all_dbcopilot_pipeline', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourceGroups/common-ai-dev/providers/Microsoft.MachineLearningServices/workspaces/common-ai-dev-ml?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/bright_cumin_384gpfjhy6?wsid=/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourcegroups/common-ai-dev/workspaces/common-ai-dev-ml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Submit pipeline job\n",
        "running_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job, experiment_name=str.lower(f\"{datastore_name}_{datastore_scope}_dbcopilot_pipeline\")\n",
        ")\n",
        "running_pipeline_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "c71f975c",
      "metadata": {
        "gather": {
          "logged": 1689182301371
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: bright_cumin_384gpfjhy6\n",
            "Web View: https://ml.azure.com/runs/bright_cumin_384gpfjhy6?wsid=/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourcegroups/common-ai-dev/workspaces/common-ai-dev-ml\n",
            "\n",
            "Streaming logs/azureml/executionlogs.txt\n",
            "========================================\n",
            "\n",
            "[2023-09-11 20:51:44Z] Submitting 1 runs, first five are: f36318d1:d37659bf-2f2a-4c1f-8772-d68af2818dcb\n",
            "[2023-09-11 21:00:24Z] Execution of experiment failed, update experiment status and cancel running nodes.\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: bright_cumin_384gpfjhy6\n",
            "Web View: https://ml.azure.com/runs/bright_cumin_384gpfjhy6?wsid=/subscriptions/8878a446-3d3e-44c2-bae5-09fd1d17e6d6/resourcegroups/common-ai-dev/workspaces/common-ai-dev-ml\n"
          ]
        },
        {
          "ename": "JobException",
          "evalue": "Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /llm_ingest_db_to_faiss/db_meta_loading_generator. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2023-09-11T21:00:24.342952Z\",\n    \"component_name\": \"\"\n} ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mJobException\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ml_client\u001b[39m.\u001b[39;49mjobs\u001b[39m.\u001b[39;49mstream(running_pipeline_job\u001b[39m.\u001b[39;49mname)\n",
            "File \u001b[1;32mc:\\Users\\davidtorres\\anaconda3\\envs\\AMLenv\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[1;32mc:\\Users\\davidtorres\\anaconda3\\envs\\AMLenv\\lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:263\u001b[0m, in \u001b[0;36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    262\u001b[0m     \u001b[39mwith\u001b[39;00m log_activity(logger, activity_name \u001b[39mor\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, activity_type, custom_dimensions):\n\u001b[1;32m--> 263\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\davidtorres\\anaconda3\\envs\\AMLenv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_operations.py:662\u001b[0m, in \u001b[0;36mJobOperations.stream\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[39mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[0;32m    660\u001b[0m     \u001b[39mraise\u001b[39;00m PipelineChildJobError(job_id\u001b[39m=\u001b[39mjob_object\u001b[39m.\u001b[39mid)\n\u001b[1;32m--> 662\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream_logs_until_completion(\n\u001b[0;32m    663\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runs_operations, job_object, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_datastore_operations, requests_pipeline\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requests_pipeline\n\u001b[0;32m    664\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\davidtorres\\anaconda3\\envs\\AMLenv\\lib\\site-packages\\azure\\ai\\ml\\operations\\_job_ops_helper.py:312\u001b[0m, in \u001b[0;36mstream_logs_until_completion\u001b[1;34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[0m\n\u001b[0;32m    310\u001b[0m         file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[39mraise\u001b[39;00m JobException(\n\u001b[0;32m    313\u001b[0m             message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException : \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(json\u001b[39m.\u001b[39mdumps(error, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)),\n\u001b[0;32m    314\u001b[0m             target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[0;32m    315\u001b[0m             no_personal_data_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mException raised on failed job.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    316\u001b[0m             error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mSYSTEM_ERROR,\n\u001b[0;32m    317\u001b[0m         )\n\u001b[0;32m    319\u001b[0m file_handle\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    320\u001b[0m file_handle\u001b[39m.\u001b[39mflush()\n",
            "\u001b[1;31mJobException\u001b[0m: Exception : \n {\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Pipeline has failed child jobs. Failed nodes: /llm_ingest_db_to_faiss/db_meta_loading_generator. For more details and logs, please go to the job detail page and check the child jobs.\",\n        \"message_format\": \"Pipeline has failed child jobs. {0}\",\n        \"message_parameters\": {},\n        \"reference_code\": \"PipelineHasStepJobFailed\",\n        \"details\": []\n    },\n    \"environment\": \"eastus\",\n    \"location\": \"eastus\",\n    \"time\": \"2023-09-11T21:00:24.342952Z\",\n    \"component_name\": \"\"\n} "
          ]
        }
      ],
      "source": [
        "ml_client.jobs.stream(running_pipeline_job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d098fccd",
      "metadata": {},
      "source": [
        "## Use DBCopilot with Promptflow\n",
        "After the pipeline complete, it will create a promptflow which could be used to chat with the db."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
